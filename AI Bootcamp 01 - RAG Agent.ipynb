{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761cedb8",
   "metadata": {},
   "source": [
    "# AI Bootcamp 01 - RAG Agent by Waldemir Cambiucci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2229ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import faiss\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a864b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\", \"YOUR_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0101ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGAgent:\n",
    "    def __init__(self, model=\"gpt-3.5-turbo\", embedding_model=\"text-embedding-ada-002\"):\n",
    "        self.model = model\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        # Initialize FAISS index (Inner Product - IP)\n",
    "        self.dimension = 1536  # Standard size for \"text-embedding-ada-002\"\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "\n",
    "        # Store texts and embeddings for reference\n",
    "        self.knowledge_texts = []\n",
    "        self.knowledge_embeddings = None\n",
    "\n",
    "    def embed_text(self, text):\n",
    "        \"\"\"Uses OpenAI's API to generate text embeddings.\"\"\"\n",
    "        response = client.embeddings.create(\n",
    "            input=[text],\n",
    "            model=self.embedding_model\n",
    "        )\n",
    "        return np.array(response.data[0].embedding, dtype=np.float32)\n",
    "\n",
    "    def add_knowledge(self, texts):\n",
    "        \"\"\"\n",
    "        Takes a list of texts (knowledge base), generates embeddings,\n",
    "        and updates the FAISS index.\n",
    "        \"\"\"\n",
    "        for text in texts:\n",
    "            self.knowledge_texts.append(text)\n",
    "\n",
    "        # Generate embeddings for each text\n",
    "        embeddings = [self.embed_text(t) for t in texts]\n",
    "        embeddings = np.vstack(embeddings)\n",
    "\n",
    "        # Store embeddings\n",
    "        if self.knowledge_embeddings is None:\n",
    "            self.knowledge_embeddings = embeddings\n",
    "        else:\n",
    "            self.knowledge_embeddings = np.vstack([self.knowledge_embeddings, embeddings])\n",
    "\n",
    "        # Add to FAISS index\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "    def retrieve_relevant_chunks(self, query, top_k=3):\n",
    "        \"\"\"\n",
    "        Takes a user query, generates an embedding, and searches FAISS\n",
    "        for the most relevant text chunks.\n",
    "        \"\"\"\n",
    "        query_embedding = self.embed_text(query).reshape(1, -1)\n",
    "\n",
    "        # Search index (Inner Product similarity)\n",
    "        scores, indices = self.index.search(query_embedding, top_k)\n",
    "\n",
    "        # Retrieve corresponding texts\n",
    "        relevant_texts = []\n",
    "        for idx in indices[0]:\n",
    "            relevant_texts.append(self.knowledge_texts[idx])\n",
    "\n",
    "        return relevant_texts\n",
    "\n",
    "    def generate_answer(self, query, relevant_texts):\n",
    "        \"\"\"\n",
    "        Combines retrieved text chunks with the user query\n",
    "        to form a prompt and calls OpenAI's API for the final answer.\n",
    "        \"\"\"\n",
    "        context = \"\\n\\n\".join(relevant_texts)\n",
    "        system_prompt = (\n",
    "            \"Você é um assistente especializado neste domínio. \"\n",
    "            \"Use o contexto a seguir para responder de forma clara e objetiva.\\n\\n\"\n",
    "            f\"Contexto:\\n{context}\\n\\n\"\n",
    "        )\n",
    "        user_prompt = f\"Pergunta: {query}\\nResposta:\"\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=300\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content.strip()\n",
    "\n",
    "    def answer_query(self, query, top_k=3):\n",
    "        \"\"\"\n",
    "        Main function:\n",
    "        1. Retrieves relevant text chunks\n",
    "        2. Generates a response using context\n",
    "        \"\"\"\n",
    "        relevant_texts = self.retrieve_relevant_chunks(query, top_k=top_k)\n",
    "        return self.generate_answer(query, relevant_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f4869dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta: Explique a biblioteca FAISS.\n",
      "Resposta: A biblioteca FAISS é uma ferramenta de código aberto utilizada para indexação e busca eficiente de vetores. Ela é amplamente utilizada em aplicações que envolvem grandes conjuntos de dados vetoriais, como processamento de linguagem natural, reconhecimento de imagens e recomendação de conteúdo. A FAISS oferece algoritmos otimizados para realizar operações de busca e recuperação de informações de forma rápida e eficaz.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------- USAGE --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example knowledge base\n",
    "    knowledge_base = [\n",
    "        \"A linguagem Python é muito utilizada para análise de dados, inteligência artificial e desenvolvimento web.\",\n",
    "        \"RAG (Retrieval-Augmented Generation) combina recuperação de informações relevantes e geração de texto.\",\n",
    "        \"OpenAI oferece APIs para modelos de linguagem, como GPT-3.5, e para embeddings, como text-embedding-ada-002.\",\n",
    "        \"FAISS é uma biblioteca de código aberto para indexação e busca vetorial eficiente.\"\n",
    "    ]\n",
    "\n",
    "    # Instantiate and inject knowledge\n",
    "    agent = RAGAgent()\n",
    "    agent.add_knowledge(knowledge_base)\n",
    "\n",
    "    # Example query\n",
    "    # user_query = \"O que é RAG e como posso usar Python para implementar?\"\n",
    "    user_query = \"Explique a biblioteca FAISS.\"\n",
    "\n",
    "    # Generate response\n",
    "    answer = agent.answer_query(user_query, top_k=2)\n",
    "    print(\"Pergunta:\", user_query)\n",
    "    print(\"Resposta:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213a6059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
